"""
v18 â†’ v19 ì¶”ê°€ íŒ¨ì¹˜:
1. conf_logits NaN: _fail_if_nonfinite ì´ì „ì— conf_logitsë„ nan_to_numìœ¼ë¡œ sanitize
2. ì§„ì§œ ì›ì¸: predsì— nonfinite â†’ run_epochì—ì„œ preds/conf_logitsë„ ì²´í¬ í›„ skip
3. AMP í™˜ê²½ì—ì„œ conf_logits FP16 ì˜¤ë²„í”Œë¡œìš° ë°©ì§€: ConfidenceHead forwardì—ì„œ clamp
4. EGNN coord_update í­ë°œ ë°©ì§€: agg_dxë¥¼ clamp (coord_step_scale ë§ê³  ì¶”ê°€ clamp)
5. _fail_if_nonfinite: preds nonfiniteë„ skip ì¡°ê±´ìœ¼ë¡œ ì¶”ê°€ (loss ì´ì™¸ì—ë„)
6. cfg.amp = False ë¡œ ê³ ì • (FP16 ìì²´ë¥¼ ë„ëŠ” ê²Œ ê°€ì¥ ì•ˆì „)
"""
import json, re

SRC = "improve_data_label_v18.ipynb"
DST = "improve_data_label_v19.ipynb"

with open(SRC, "r", encoding="utf-8") as f:
    nb = json.load(f)

def cell_src(cell):
    return "".join(cell["source"])

def set_src(cell, text):
    lines = text.split("\n")
    result = [l + "\n" for l in lines]
    if result and result[-1] == "\n":
        result[-1] = ""
    cell["source"] = result

patched = 0

for cell in nb["cells"]:
    if cell["cell_type"] != "code":
        continue
    src = cell_src(cell)

    # â”€â”€ FIX A: AMPë¥¼ ë” (FP16 ì˜¤ë²„í”Œë¡œìš°ê°€ ê·¼ë³¸ ì›ì¸) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    OLD_AMP = "    amp: bool = True             # âœ… í•„ìš”í•˜ë©´ Falseë¡œ êº¼ì„œ NaN ì—¬ë¶€ í™•ì¸"
    NEW_AMP = "    amp: bool = False            # âœ… v19: FP16 conf_logits/preds overflow ë°©ì§€ â†’ AMP OFF"
    if OLD_AMP in src:
        src = src.replace(OLD_AMP, NEW_AMP)
        print("âœ… FIX A: amp=False (AMP ë¹„í™œì„±í™”)")
        patched += 1

    # â”€â”€ FIX B: run_epoch - preds/conf_logitsë„ nonfiniteë©´ skip â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    OLD_SKIP = '''\
            # âœ… v18: non-finite loss â†’ skip step (log warning) instead of hard crash
            if not torch.isfinite(loss):
                print(f"[NaN/skip] epoch={epoch} step={step} train={train}  loss={loss.item()}  stage={stage_name} â€” skipping batch")
                if train:
                    opt.zero_grad(set_to_none=True)
                continue'''
    NEW_SKIP = '''\
            # âœ… v19: non-finite loss OR preds OR conf_logits â†’ skip step
            _preds_ok = torch.isfinite(preds).all()
            _conf_ok  = (conf_logits is None) or torch.isfinite(conf_logits).all()
            _loss_ok  = torch.isfinite(loss)
            if not (_loss_ok and _preds_ok and _conf_ok):
                print(f"[NaN/skip] epoch={epoch} step={step} train={train}  "
                      f"loss_ok={bool(_loss_ok.item())}  preds_ok={bool(_preds_ok.item())}  conf_ok={bool(_conf_ok.item() if hasattr(_conf_ok,'item') else _conf_ok)}  "
                      f"stage={stage_name} â€” skipping batch")
                if train:
                    opt.zero_grad(set_to_none=True)
                continue'''
    if OLD_SKIP in src:
        src = src.replace(OLD_SKIP, NEW_SKIP)
        print("âœ… FIX B: run_epoch preds/confë„ nonfinite skip")
        patched += 1

    # â”€â”€ FIX C: ConfidenceHead.forward â†’ output clamp & nan_to_num â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    OLD_CONF_FWD = '''\
    def forward(self, h, pad_mask):
        if pad_mask is None:
            pooled = h.mean(dim=1)
        else:
            m = pad_mask.float().unsqueeze(-1)
            denom = m.sum(dim=1).clamp_min(1.0)
            pooled = (h * m).sum(dim=1) / denom
        return self.mlp(pooled)  # (B,K)'''
    NEW_CONF_FWD = '''\
    def forward(self, h, pad_mask):
        if pad_mask is None:
            pooled = h.mean(dim=1)
        else:
            m = pad_mask.float().unsqueeze(-1)
            denom = m.sum(dim=1).clamp_min(1.0)
            pooled = (h * m).sum(dim=1) / denom
        out = self.mlp(pooled)  # (B,K)
        # âœ… v19: AMP FP16ì—ì„œ overflow â†’ NaN/Inf ë°©ì§€
        out = torch.nan_to_num(out.float(), nan=0.0, posinf=20.0, neginf=-20.0).clamp(-30.0, 30.0)
        return out'''
    if OLD_CONF_FWD in src:
        src = src.replace(OLD_CONF_FWD, NEW_CONF_FWD)
        print("âœ… FIX C: ConfidenceHead output nan_to_num + clamp")
        patched += 1

    # â”€â”€ FIX D: EGNNv16.forward - preds nan_to_num guard ì¶”ê°€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    OLD_PREDS_MASK = '''\
        preds = preds.masked_fill(~pad_mask[:, None, :, None], 0.0)

        conf_logits = self.conf_head(h, pad_mask)  # (B,K)
        return preds, conf_logits'''
    NEW_PREDS_MASK = '''\
        preds = preds.masked_fill(~pad_mask[:, None, :, None], 0.0)
        # âœ… v19: EGNN ëˆ„ì  í­ë°œ ë°©ì§€ (agg_dx index_add_ overflow)
        preds = torch.nan_to_num(preds, nan=0.0, posinf=1e4, neginf=-1e4)
        preds = preds.clamp(-1e4, 1e4)

        conf_logits = self.conf_head(h, pad_mask)  # (B,K)
        return preds, conf_logits'''
    if OLD_PREDS_MASK in src:
        src = src.replace(OLD_PREDS_MASK, NEW_PREDS_MASK)
        print("âœ… FIX D: EGNNv16 preds nan_to_num + clamp")
        patched += 1

    # â”€â”€ FIX E: EGNNPairAwareLayer - agg_dx clamp â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    OLD_AGGDX = '''\
        if node_mask is not None:
            agg_dx = agg_dx.masked_fill(~node_mask[:, :, None], 0.0)
            agg_m  = agg_m.masked_fill(~node_mask[:, :, None], 0.0)

        x = x + agg_dx'''
    NEW_AGGDX = '''\
        if node_mask is not None:
            agg_dx = agg_dx.masked_fill(~node_mask[:, :, None], 0.0)
            agg_m  = agg_m.masked_fill(~node_mask[:, :, None], 0.0)

        # âœ… v19: coord í­ë°œ ë°©ì§€ clamp (coord_step_scale ì´í›„ì—ë„ ëˆ„ì ë  ìˆ˜ ìˆìŒ)
        agg_dx = agg_dx.clamp(-5.0, 5.0)
        x = x + agg_dx'''
    if OLD_AGGDX in src:
        src = src.replace(OLD_AGGDX, NEW_AGGDX)
        print("âœ… FIX E: EGNNPairAwareLayer agg_dx clamp(-5,5)")
        patched += 1

    # â”€â”€ FIX F: cfg í—¤ë” ì£¼ì„ ì—…ë°ì´íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    src = src.replace("[v18]", "[v19]").replace("[v16]", "[v19]")

    set_src(cell, src)

print(f"\nTotal patches: {patched}/5")

with open(DST, "w", encoding="utf-8") as f:
    json.dump(nb, f, ensure_ascii=False, indent=1)

print(f"ğŸ’¾ Saved â†’ {DST}")
